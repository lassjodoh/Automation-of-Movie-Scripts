{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e07de8",
   "metadata": {},
   "source": [
    "## Movie Cleaning and Pre-processing\n",
    "\n",
    "+ The main purpose of this notebook is to clean and pre-process the data obtained from the website\n",
    "   + imsdb.com and imdb.com\n",
    "\n",
    "##### This notebook accomplishes four primary tasks:\n",
    "\n",
    "+ using the regex library, replace the contracted words in the dataset models\n",
    "  + such as, can't - cannot,\n",
    "    've - have,\n",
    "    I'm - I am\n",
    "+ eliminate punctuation and stop words, so also multiple names reoccurring in the beginning of dialogues.\n",
    "+ replace and sort the data\n",
    "+ save the cleaned data for analysis and modelling\n",
    "---\n",
    "\n",
    "+ import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b81743b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2322b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ojoho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2734025",
   "metadata": {},
   "source": [
    "This function below replaces the contracted words in the data and replaces it with its proper extension. This was done prior so it wouldn't be affected by the punction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "958e4dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_clean(text):\n",
    "    '''words like can't can't be processed properly, words ending with 's replaced to is and 'll as will ''' \n",
    "    text = re.sub(r\"can't\", \"can not\", text)\n",
    "    text = re.sub(r\"\\'s+\", \" is\", text)\n",
    "    text = re.sub(r\"\\'ll+\", \" will\", text)\n",
    "    text = re.sub(r\"\\'re+\", \" are\", text)\n",
    "    text = re.sub(r\"[n]\\'t+\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"[n]\\'\", \" not\", text)\n",
    "    text = re.sub(r\"[^a-zA-z]ll[^a-zA-z]\", \" will\", text)\n",
    "    text = re.sub(r\"[^a-zA-z]re[^a-zA-z]\", \" are\", text)\n",
    "    text = re.sub(r\"[^a-zA-z]ve[^a-zA-z]\", \" have\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2a15cf",
   "metadata": {},
   "source": [
    "## Speaker Cues and Transitions\n",
    "---\n",
    "+ Speaker cues and transitions in the data were all expressed in Uppercase. So multiple functions were created to \n",
    "  + segregate data in uppercase and eliminate all words appearing more than 10 times from the dataset. \n",
    "    This was done to minimize the character names in the dataset.\n",
    "  + Punctuations and stopwords were eliminated from the text as well.\n",
    "  + script to be tokenized\n",
    "  + data to be lemmatized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce516472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elimate_multiple(new_d):\n",
    "    '''The regex takes into account all values that have 2 uppercase letters consecutively\n",
    "    it then does a count of all the letters in uppercase and returns it to the next fuction'''\n",
    "    capital_letters = re.findall('[A-Z][A-Z]+', new_d)\n",
    "    frequency = ' '.join(capital_letters)\n",
    "    counts = dict()\n",
    "    words = frequency.split()\n",
    "    for word in words:\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1        \n",
    "    return counts\n",
    "\n",
    "def remove_values(counts):\n",
    "    #This function elimates words with multiple occurance based on its counts \n",
    "    repeated_words = []\n",
    "    for key,value in counts.items():\n",
    "        if value > 10:\n",
    "            repeated_words.append(key)\n",
    "        else:\n",
    "            key.lower()\n",
    "    return repeated_words  \n",
    "\n",
    "def clean_text(text):\n",
    "    #Make text lowercase, remove text in square brackets, remove punctuation and remove numbers.\n",
    "    #text = text.lower()\n",
    "    text = initial_clean(text)\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    stop_words = remove_values(elimate_multiple(text))\n",
    "    for i in stop_words:\n",
    "        text = re.sub(f'[^A-Za-z]{i}[^A-Za-z]', ' ', text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "def clean_stopword(x):\n",
    "    #clean stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    for name in stop_words:#issue with capital letters and lower letters\n",
    "        return \" \".join([w.lower() for w in x.split() if w.lower() not in stop_words and len(w) > 1])\n",
    "\n",
    "def lemmatize(x):\n",
    "    # tokenize and lemmatize the data\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_word = clean_stopword(x)\n",
    "    tokenized_word = [lemmatizer.lemmatize(word) for word in clean_word]\n",
    "    return \"\".join(tokenized_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b9bb18",
   "metadata": {},
   "source": [
    "Using Pandas we read into our uncleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34552607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('movie_dataBase.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84710624",
   "metadata": {},
   "source": [
    "Eliminating missing data: Some Urls on the website were inconsistent causing absent scripts and age rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b5963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Movie_Script'] = df['Movie_Script'].astype('string') #convert from datatype object to string\n",
    "df.dropna(subset=['Movie_Script'], inplace=True) #empty rows are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fee90dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final_text'] = df['Movie_Script'].apply(lambda x : clean_text(x)) #applying clean_text function\n",
    "df['final_text2'] = df['final_text'].apply(lambda x : lemmatize(x)) # lemmatize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d83225",
   "metadata": {},
   "source": [
    "Age Rating. values were substituted and grouped into 4 different ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f49c4407",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_rating = {'12A': '12',\n",
    "              'U':'PG',\n",
    "              'AA': '15',\n",
    "              'X': '18',\n",
    "              'TV-MA': '18',\n",
    "              'Adult':'18',\n",
    "              'Passed': '12',\n",
    "              'PG-13': '12',\n",
    "              'TV-14': '15',\n",
    "              'A':'18',\n",
    "              'R': '18',\n",
    "              'Not Rated': np.nan,\n",
    "              ' ' : np.nan\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ae410a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_rating'] = df['age_rating'].replace(age_rating)\n",
    "df.dropna(subset=['age_rating'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef95951",
   "metadata": {},
   "source": [
    "Movie Genre. \n",
    "---\n",
    "+ a genre_type Music and Musical were substituted based on similarity. \n",
    "+ column was further cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ab1cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Movie_Genre'] = df['Movie_Genre'].str[1:-1].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67d52b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_genre(text):\n",
    "    text = re.sub('Musical', 'Music', text)\n",
    "    text = re.sub(\"'\", '', text)\n",
    "    text = re.sub(r\"\\.\", \",\", text)\n",
    "    text = re.sub(' ', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64b6c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Movie_Genre'] = df['Movie_Genre'].apply(lambda x : clean_genre(x)) #function is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff504b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mystery', 'History', 'Biography', 'Crime', 'Sci-Fi', 'Romance', 'Horror', 'Action', 'Film-Noir', 'Family', 'War', 'Music', 'Animation', 'Sport', 'Fantasy', 'Thriller', 'Western', 'Comedy', 'Drama', 'Adventure']\n"
     ]
    }
   ],
   "source": [
    "# Returns the unique genres based on splitting entire column to list. A set is used because it doesn't give room for repitition\n",
    "unique_genres = list(set([y for x in df['Movie_Genre'] for y in x.split(',')]))\n",
    "print (unique_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e26baf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>age_rating</th>\n",
       "      <th>Movie_Genre</th>\n",
       "      <th>Movie_Script</th>\n",
       "      <th>final_text</th>\n",
       "      <th>final_text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reservoir Dogs</td>\n",
       "      <td>18</td>\n",
       "      <td>Action,Crime,Thriller</td>\n",
       "      <td>Quentin Tara...</td>\n",
       "      <td>Quentin Tara...</td>\n",
       "      <td>quentin tarantino october movie dedicated foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to Train Your Dragon</td>\n",
       "      <td>PG</td>\n",
       "      <td>Animation,Adventure,Comedy</td>\n",
       "      <td>HOW TO TRAIN YO...</td>\n",
       "      <td>HOW TRAIN YOUR ...</td>\n",
       "      <td>train dragon written dean deblois chris sander...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scream</td>\n",
       "      <td>18</td>\n",
       "      <td>Horror,Mystery,Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>scream scary movie kevin williamson rewrite ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Groundhog Day</td>\n",
       "      <td>PG</td>\n",
       "      <td>Comedy,Fantasy,Romance</td>\n",
       "      <td>GROUNDH...</td>\n",
       "      <td>GROUNDH...</td>\n",
       "      <td>groundhog written danny rubin second revision ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black Panther</td>\n",
       "      <td>12</td>\n",
       "      <td>Action,Adventure,Sci-Fi</td>\n",
       "      <td>BLACK PANTHER  ...</td>\n",
       "      <td>BLACK PANTHER  ...</td>\n",
       "      <td>black panther written ryan coogler joe robert ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>You Can Count On Me</td>\n",
       "      <td>15</td>\n",
       "      <td>Drama</td>\n",
       "      <td>\"YOU CAN COU...</td>\n",
       "      <td>YOU CAN COUN...</td>\n",
       "      <td>count screenplay kenneth lonergan shooting dra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>You've Got Mail</td>\n",
       "      <td>PG</td>\n",
       "      <td>Comedy,Romance</td>\n",
       "      <td>You've Got Mail    \t\t\tYou've Got Mail  \t\t\tby...</td>\n",
       "      <td>You have Got Mail    \\t\\t\\tYou have Got Mail...</td>\n",
       "      <td>got mail got mail nora ephron delia ephron bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>Youth in Revolt</td>\n",
       "      <td>15</td>\n",
       "      <td>Comedy,Drama,Romance</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>youth revolt written gustin nash july black co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>Zero Dark Thirty</td>\n",
       "      <td>15</td>\n",
       "      <td>Drama,Thriller</td>\n",
       "      <td>ZERO DARK...</td>\n",
       "      <td>ZERO DARK...</td>\n",
       "      <td>zero dark thirty written mark boal october voi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>Zootopia</td>\n",
       "      <td>PG</td>\n",
       "      <td>Animation,Adventure,Comedy</td>\n",
       "      <td>ZOOTOPIA      ...</td>\n",
       "      <td>...</td>\n",
       "      <td>written jared bush phil johnston story byron h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1046 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title age_rating                 Movie_Genre  \\\n",
       "0               Reservoir Dogs         18       Action,Crime,Thriller   \n",
       "1     How to Train Your Dragon         PG  Animation,Adventure,Comedy   \n",
       "2                       Scream         18     Horror,Mystery,Thriller   \n",
       "3                Groundhog Day         PG      Comedy,Fantasy,Romance   \n",
       "4                Black Panther         12     Action,Adventure,Sci-Fi   \n",
       "...                        ...        ...                         ...   \n",
       "1207       You Can Count On Me         15                       Drama   \n",
       "1208           You've Got Mail         PG              Comedy,Romance   \n",
       "1209           Youth in Revolt         15        Comedy,Drama,Romance   \n",
       "1210          Zero Dark Thirty         15              Drama,Thriller   \n",
       "1212                  Zootopia         PG  Animation,Adventure,Comedy   \n",
       "\n",
       "                                           Movie_Script  \\\n",
       "0                                       Quentin Tara...   \n",
       "1                                    HOW TO TRAIN YO...   \n",
       "2                                                   ...   \n",
       "3                                            GROUNDH...   \n",
       "4                                    BLACK PANTHER  ...   \n",
       "...                                                 ...   \n",
       "1207                                    \"YOU CAN COU...   \n",
       "1208    You've Got Mail    \t\t\tYou've Got Mail  \t\t\tby...   \n",
       "1209                                                ...   \n",
       "1210                                       ZERO DARK...   \n",
       "1212                                  ZOOTOPIA      ...   \n",
       "\n",
       "                                             final_text  \\\n",
       "0                                       Quentin Tara...   \n",
       "1                                    HOW TRAIN YOUR ...   \n",
       "2                                                   ...   \n",
       "3                                            GROUNDH...   \n",
       "4                                    BLACK PANTHER  ...   \n",
       "...                                                 ...   \n",
       "1207                                    YOU CAN COUN...   \n",
       "1208    You have Got Mail    \\t\\t\\tYou have Got Mail...   \n",
       "1209                                                ...   \n",
       "1210                                       ZERO DARK...   \n",
       "1212                                                ...   \n",
       "\n",
       "                                            final_text2  \n",
       "0     quentin tarantino october movie dedicated foll...  \n",
       "1     train dragon written dean deblois chris sander...  \n",
       "2     scream scary movie kevin williamson rewrite ju...  \n",
       "3     groundhog written danny rubin second revision ...  \n",
       "4     black panther written ryan coogler joe robert ...  \n",
       "...                                                 ...  \n",
       "1207  count screenplay kenneth lonergan shooting dra...  \n",
       "1208  got mail got mail nora ephron delia ephron bas...  \n",
       "1209  youth revolt written gustin nash july black co...  \n",
       "1210  zero dark thirty written mark boal october voi...  \n",
       "1212  written jared bush phil johnston story byron h...  \n",
       "\n",
       "[1046 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b9c381",
   "metadata": {},
   "source": [
    "### Saving cleaned dataFrame to a csv for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4eac5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_dataBase.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b1f9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
